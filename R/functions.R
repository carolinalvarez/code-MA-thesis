#' Author: Carolina Alvarez
#' Code with functions used in the simulation study
#' 
#' 
#' Data Generation Process following Fithian and Hastie 
#'
#' Generates data set that is flexible in amount of imbalance, size of training set and class overlapping 
#' (?) also distribution from which coufounders are drawn 
#' I think this will make the class overlapping flexible in the mean parameters?
#' parameter c: the proportion of 0's we want in the data


gdp.imbalanced <- function(N
                           , r
                           , distribution
                           , k
                           , mean1
                           , mean0
                           , sigma1
                           , sigma0) {
  
  n_class1 <- ceiling(N * (1-r))
  n_class0 <- ceiling(N * r)
  
  y0 <- rep(0, n_class0)
  y1 <- rep(1, n_class1)
  
  if (distribution=="gaussian"){
    X_class1 <- matrix(mvrnorm(n_class1, mu = mean1, Sigma = sigma1, empirical = TRUE), ncol = k)
    X_class1 <- cbind(y1, X_class1)
    
    X_class0 <- matrix(mvrnorm(n_class0, mu = mean0, Sigma = sigma0, empirical = TRUE), ncol = k)
    X_class0 <- cbind(y0, X_class0)
    
    df <- as.data.frame(rbind(X_class1, X_class0))
    
    colnames(df) <- c("y", paste0("X", 1:k))
    
    return(df)
    
  }
  else{
    stop("Distribution not allowed.")
  }
  
}


get.true.intercept <- function(r, x0, betas){
  #' The function allows to recover the true intercept for a given value of r 
  #' the complexity of generating the simulated dataset specifically for fixed 
  #' percentages of r requires b0 values to vary for different r
  #' 
  #' r (numeric, percentage): imbalanced ratio, % of '1'
  #' x0 (numeric or vector): fixed value for X_k
  #' betas (numeric or vector): fixed value for beta_k
  
  
  beta_0 <- log(r) - log(1-r) - t(x0)%*%betas
  return(as.numeric(beta_0))
  
}

get.true.intercept(0.02, c(0.5, 0.5, 0.5), c(1, 1, 1))

#' Case-Control subsampling by Fithian and Hastie 
#'
#' Algorithm for subsampling and fitting a logistic regression in the data
#' hyperparameter a(y): the proportion of 1's we want to subsample. The subsample is generated by first generating 
#' ui ~ U(0,1) that is mutually intedepndent from the pilot (?), the data and each other. Then zi ~ 1 if ui<=a(yi)


cc_algorithm <- function(data, a){
  
  k <- length(data) - 1 # we take "y" out
  
  selection_bias <- log(a/(1-a))
  
  prob_function <- function(data, a){
    
    data$a <- ifelse(data$y == 0, 1 - a, a)
    
    return(data)
  }
  
  tmp01 <- prob_function(data, a)
  
  U <- runif(nrow(data), 0, 1)
  tmp01$U <- U
  
  tmp01$Z <- NA
  tmp01$Z <- ifelse(tmp01$U <= tmp01$a, 1, 0)
  
  #Subsample
  tmp02 <- tmp01[tmp01$Z==1, ] 
  class_distr_subsample <- table(tmp02$y)
  
  xvars <- paste("X", 1:k, sep="")
  
  model_subsample <- glm(as.formula(paste("y ~ ", paste(xvars, collapse= "+")))
                         , data= tmp02
                         , family = binomial) #imp: remove a to avoid perfect separation and convergence issues
  
  coef_unadjusted <- as.vector(model_subsample$coefficients)
  
  beta0_adjusted <- coef_unadjusted[1] - selection_bias
  
  coef_adjusted <- c(beta0_adjusted, coef_unadjusted[2:(k+1)])
  
  res <- list("subsample_S" = tmp02
              , "coef_unadjusted" = coef_unadjusted
              , "coef_adjusted" = coef_adjusted
              )
  
  return(res)
  
}



#' Prediction function
#' A flexible function of predicting odds logistic regression framework
#' 
logit_predict <- function(data, names.use, betas){
  # data (dataframe): test set
  # names.use (vector): vector containing strings with names of features (columns of 'data')
  # betas (vector): vector containing beta coefficients, including intercept (IMP for Fithian and Hastie (2014))
  # For cc, betas is the vector of adjusted coef
  
  X <- as.matrix(cbind(rep(1), data[, names.use]))
  colnames(X) <- c("intercept", names.use)
  n <- nrow(X)
  p <- ncol(X)
  p1 <- seq_len(p) 
  beta <- betas 
  predictor_vector <- 1/(1+exp((-1)*drop(X[, p1, drop = FALSE] %*% beta[p1])))
  return(predictor_vector)
  
}




#' Stratified hold-out method / Generation of train and test sets
#' Function assures that class distribution p(x) of 'y' remains

strat_sampling <- function(data, split_criteria){
  #' data (dataframe): data to split into train and test set
  #' split_criteria (numeric): percentage of observations assigned to the train set
  
  train_idx <- c()
  test_idx <- c()
  
  for (i in c('0', '1')) {
    
    idx <- which(data$y == i)
    n_train <- round(length(idx) * split_criteria) 
    
    train_idx_i <- sample(idx, n_train)
    test_idx_i <- setdiff(idx, train_idx_i)
    train_idx <- c(train_idx, train_idx_i)
    test_idx <- c(test_idx, test_idx_i)
  
    }
  
  # Create train and test sets
  df_train <- data[train_idx, ]
  df_test <- data[test_idx, ]
  
  res <- list("df_train" = df_train
              , "df_test" = df_test)
  
  return(res)
  
}

# Proving I get the same prob and ratios as equations for CC

a_bar <- function(a, r){
  a_bar <- a*(1-r) + (1-a) * r
  return(a_bar)
}

prop_Ps <-function(a, r){
  a1 <- a
  a0 <- 1-a
  
  prop_Ps_1 <- (a1 * (1-r))/ (a1*(1-r) + a0*r)
  prop_Ps_0 <- (a0 * r)/ (a1*(1-r) + a0*r)
  
  c <- c(prop_Ps_0, prop_Ps_1)
  
  return(c)
}


# Function for taking N_s


gdp.imbalanced.Ns <- function(a
                              , r
                              , distribution
                              , Ns_size
                              , k
                              , mean1
                              , mean0
                              , sigma1
                              , sigma0){

  prop_Ps <- prop_Ps(a, r)
  
  prop_Ps_1 <- as.numeric(prop_Ps[2])
  prop_Ps_1 <- round(prop_Ps_1, 1)
  
  prop_Ps_0 <- as.numeric(prop_Ps[1])
  prop_Ps_0 <- round(prop_Ps_0, 1)
  
  N <- Ns_size
  
  # now the usual dgp
  n_class1 <- ceiling(N * prop_Ps_1)
  n_class0 <- ceiling(N * prop_Ps_0)
  
  y0 <- rep(0, n_class0)
  y1 <- rep(1, n_class1)
  
  if (distribution=="gaussian"){
    
    X_class1 <- matrix(mvrnorm(n_class1, mu = mean1, Sigma = sigma1, empirical = TRUE), ncol = k)
    X_class1 <- cbind(y1, X_class1)
    
    X_class0 <- matrix(mvrnorm(n_class0, mu = mean0, Sigma = sigma0, empirical = TRUE), ncol = k)
    X_class0 <- cbind(y0, X_class0)
    
    df <- as.data.frame(rbind(X_class1, X_class0))
    
    colnames(df) <- c("y", paste0("X", 1:k))
    
    return(df)
    
  }
  else{
    stop("Distribution not allowed.")
  }
  
  
}


# Function for WCC sampling 
# 1st. Trial: Not adjusting the coefficient of the intercept (it does not seem like they do...)


wcc_algorithm <- function(data, a){
  
  k <- length(data) - 1 # we take "y" out
  
  selection_bias <- log(a/(1-a))
  
  prob_function <- function(data, a){
    
    data$a <- ifelse(data$y == 0, 1 - a, a)
    
    return(data)
  }
  
  tmp01 <- prob_function(data, a)
  
  U <- runif(nrow(data), 0, 1)
  tmp01$U <- U
  
  tmp01$Z <- NA
  tmp01$Z <- ifelse(tmp01$U <= tmp01$a, 1, 0)
  
  #Subsample
  tmp02 <- tmp01[tmp01$Z==1, ] 
  class_distr_subsample <- table(tmp02$y)
  
  #weights vector
  tmp02$w <- 1/tmp02$a
  
  
  xvars <- paste("X", 1:k, sep="")
  
  # https://github.com/alan-turing-institute/PosteriorBootstrap/issues/16 on why to use quasibinomial instead of binomial
  model_subsample <- glm(as.formula(paste("y ~ ", paste(xvars, collapse= "+")))
                         , data= tmp02
                         , family = quasibinomial()
                         , weights = w) #imp: remove a to avoid perfect separation and convergence issues
  
  coef_unadjusted <- as.vector(model_subsample$coefficients)
  
  # beta0_adjusted <- coef_unadjusted[1] - selection_bias
  # 
  # coef_adjusted <- c(beta0_adjusted, coef_unadjusted[2:(k+1)])
  
  res <- list("subsample_S" = tmp02
              , "coef_unadjusted" = coef_unadjusted
              #, "coef_adjusted" = coef_adjusted
  )
  
  return(res)
  
}
  




wcc_algorithm_2 <- function(data, a){
  
  k <- length(data) - 1 # we take "y" out
  
  selection_bias <- log(a/(1-a))
  
  prob_function <- function(data, a){
    
    data$a <- ifelse(data$y == 0, 1 - a, a)
    
    return(data)
  }
  
  tmp01 <- prob_function(data, a)
  
  U <- runif(nrow(data), 0, 1)
  tmp01$U <- U
  
  tmp01$Z <- NA
  tmp01$Z <- ifelse(tmp01$U <= tmp01$a, 1, 0)
  
  #Subsample
  tmp02 <- tmp01[tmp01$Z==1, ] 
  class_distr_subsample <- table(tmp02$y)
  
  #weights vector
  tmp02$w <- 1/tmp02$a
  
  
  xvars <- paste("X", 1:k, sep="")
  
  # https://github.com/alan-turing-institute/PosteriorBootstrap/issues/16 on why to use quasibinomial instead of binomial
  model_subsample <- glm(as.formula(paste("y ~ ", paste(xvars, collapse= "+")))
                         , data= tmp02
                         , family = quasibinomial()
                         , weights = w) #imp: remove a to avoid perfect separation and convergence issues
  
  coef_unadjusted <- as.vector(model_subsample$coefficients)
  
  beta0_adjusted <- coef_unadjusted[1] - selection_bias
  # 
  coef_adjusted <- c(beta0_adjusted, coef_unadjusted[2:(k+1)])
  
  res <- list("subsample_S" = tmp02
              , "coef_unadjusted" = coef_unadjusted
              , "coef_adjusted" = coef_adjusted
  )
  
  return(res)
  
}
      