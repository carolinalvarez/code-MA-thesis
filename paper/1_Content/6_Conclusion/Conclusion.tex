\section{Conclusion}
\label{sec:Conclusion}

In the context of large datasets, this thesis addressed the challenge of designing effective subsampling schemes for reducing computational burdens while still approximating the parameter estimates of the full sample. It has been shown that this task is particularly challenging when the data exhibits marginal or conditional imbalance, making it harder to create subsamples that balance statistical efficiency with computational gains. The study focused on case-control subsampling methods such as standard case-control (CC), weighted case-control (WCC), and local case-control (LCC), which aim to alleviate this problem by assigning different acceptance probabilities to cases and controls. It is important to note that the sample sizes used in this analysis might not correspond to massive datasets due to limitations in computational power. However, it serves to showcase a scaled-down exercise of the effectiveness of the methods under different scenarios. \\

The simulation study and data application section revealed that the performance of the methods is heavily influenced by the nature of the DGP. In this regard, their performance varies depending on factors such as the degree of marginal and conditional imbalance, the full sample size, and the extent to which their theoretical assumptions are valid. For instance, while the CC estimate seems to be the most efficient even for levels of high-to-severe marginal imbalance, it fails to exploit the conditional imbalance present in the data. The WCC estimate, on the other hand, is asymptotically unbiased and consistent and shows good efficiency for mild levels of marginal imbalance. Moreover, it serves as a pilot estimate in the first stage of the LCC procedure. Yet, one strong drawback of the method is that for large-to-severe levels of imbalance, the variance of the estimator quickly escalates, as the variation in its computational weights adds additional noise to the estimate. \\

LCC was proposed by \textcite{hastie2014} as a good alternative to CC and WCC for accounting conditional imbalance in the data and model misspecification. Although this thesis did not study LCC's behavior within misspecification, it aimed to extend the original paper's analysis and showcase LCC's performance for different DGPs. Again, the numerical exercises and real-data implementation showed that, although LCC outperforms CC and WCC for large $N$ and high levels of conditional imbalance, it still shows some drawbacks in marginal imbalanced datasets and small samples. In particular, for high-to-severe marginal imbalanced data and moderate sample sizes, LCC shows a dramatic efficiency loss, with severe inflation for both squared bias and variance. It was also suggested that the consistency of the LCC estimator could be hindered by the inconsistency of the pilot estimate in small samples. In contrast, the estimate's capability of approximating its asymptotic distribution could be affected by the use of a data-dependent pilot in finite samples, which is a direct violation of one of the estimate's asymptotic assumptions.\\

It is important to be aware of the limitations of the findings presented in this thesis. One such limitation is the interpretation of results that used fixed subsample sizes $N_s$ for comparing the methods across settings, as it was suggested in \textcite{hastie2014}. For this specific study, that entailed estimating the median subsample size for LCC and then allowing CC and WCC to have just twice as many data points as LCC. For most of the cases in the simulation study, this translated into trimming CC and WCC subsample sizes, possibly affecting their statistical performance, especially as all methods rely heavily upon large $N$ for unbiasedness and consistency. Thus, although this procedure allows for a better comparison of the estimators' performance, it should be taken into consideration when interpreting the results. \\

Nonetheless, further work has been undertaken since \textcite{hastie2014} publication on LCC. For example, \textcite{han2020local} extended the LCC framework for solving large-scale multiclass logistic regression problems and proposed a new subsampling scheme called Local Uncertainty Sampling (LUC). They proved that their method always has a lower variance as uniform subsampling, and their empirical studies show that LUC improves upon CC and LCC under several scenarios. In addition, \cite{shen2021surprise} developed a new approach based on LCC, called Surprised Sampling Design. This version not only accepts a logistic model but rather supports several loss functions, making it compatible not only with the Logit but also with a wider range of machine learning models. Finally, \textcite{wang2020rare} proved that heavily undersampling controls while maintaining the cases do not sacrifice efficiency, and their estimator has shown to have an identical asymptotic distribution as the full sample $\theta_{MLE}$. Thus, an interesting avenue for future research could be to compare LCC's performance against the above-mentioned novel estimators that aim to generalize LCC's framework and overcome its limitations.

% \cite{wang2020rare} question \cite{hastie2014} assumption that the probability of an event occurring is fixed, and in their paper, they obtain convergence rates and asymptotic distributions of parameter estimators under the assumption that both the number of cases and the number of controls are random, and they grow large in rates that the number of cases divided by the number of controls decays to zero (parrafrasear).\\

% \cite{wang2018optimal}, \cite{wang2019moreefficient}, \cite{wang2023subsampling}, \cite{han2020local}, \cite{yu2023}.

% Data dependency of the pilot! correlated with the noise. pilot not asymptotically consistent